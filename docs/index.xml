<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Raphael Tamaki's Blog</title>
<link>https://raphaeltamaki.github.io/raphaeltamaki/index.html</link>
<atom:link href="https://raphaeltamaki.github.io/raphaeltamaki/index.xml" rel="self" type="application/rss+xml"/>
<description>Personal blog on (data) science topic applied in different subject areas</description>
<generator>quarto-1.1.189</generator>
<lastBuildDate>Wed, 12 Apr 2023 22:00:00 GMT</lastBuildDate>
<item>
  <title>Forecasting Customer Lifetime Value - Why Uncertainty Matters</title>
  <dc:creator>Raphael de Brito Tamaki</dc:creator>
  <link>https://raphaeltamaki.github.io/raphaeltamaki/posts/Forecasting Customer Lifetime Value - Why Uncertainty Matters/index.html</link>
  <description><![CDATA[ 




<p>Are you bidding right on your marketing campaigns?</p>
<p><img src="https://raphaeltamaki.github.io/raphaeltamaki/posts/Forecasting Customer Lifetime Value - Why Uncertainty Matters/burning-money.jpg" class="img-fluid"></p>
<section id="digital-advertisement-under-uncertainty" class="level1">
<h1>Digital Advertisement under Uncertainty</h1>
<p>Digital advertising is a multi-billion dollar industry, amassing more than $380bi in 2022, with just Alphabet and Meta being responsible for $234bi [1]. This sizeable digital market is powered by high-performance marketing strategies developed by analysis of the advertisement environment and the Lifetime Value (LTV) estimation of customers. The LTV is arguably the most vital metric to conduct a profitable advertisement strategy because it determines how much we are willing to pay for them. After all, if we pay more than the users are worth, we are effectively losing money.</p>
<p>But while the upper limit for the <em>Cost per User</em> is clear, its optimal point is not so readily determined: it depends on how many users we expect to obtain for a given <em>Cost per User</em> and how accurate the LTV estimation is. However, forecasting the LTV of marketing campaigns has challenges that are not often seen in machine learning problems: 1) LTV is zero-inflated since most users who become mobile game players or register as customers in a store never spend a single cent. 2) The distribution of the LTV of those that do purchase something is highly skewed, i.e., most of the revenue is generated by a fraction of the users. 3) The distribution of the LTV itself changes over time, requiring the prediction algorithms to adapt quickly. 4) The marketing industry is constantly changing, with some harming the accuracy of the LTV estimation, such as Apple’s App Tracking Transparency (ATT).</p>
<p>In this context, we explain why estimating your users’ LTV uncertainty matters to achieve maximum profitability and how that can be accomplished. The <strong>first part</strong> of this series explains one way we can model the digital advertisement environment and how different assumptions for how the number of acquire users increases as we increase our ‘bid’ impact the optimal bidding strategy when there is uncertainty on LTV estimates.</p>
<p>In the <strong>second part</strong>, we introduce a code to forecast the LTV of the marketing campaigns using PySTAN. PySTAN is a Python interface to STAN, a package for Bayesian inference capable of high-performance statistical computation. This computation speed is essential in a marketing context, where we need to predict the LTV of multiple marketing campaigns over a long period while estimating the LTV distribution. We demonstrate how to implement a PySTAN model to predict a time series using the <a href="https://www.kaggle.com/datasets/baetulo/lifetime-value?resource=download">Lifetime Value data from Kaggle</a> in less than 2 minutes. This data contains user-level information of customers joining a website, such as their country, credit card level, a product acquired when they entered the website, short-term value, and (of course) their lifetime value. We transform this user-level data into segment-level by grouping users to simulate a marketing campaign. We finish by explaining how to implement the equivalent model in PyMC, a probabilistic programming library for Python, and comparing the pros and cons of both alternatives.</p>
</section>
<section id="part-1-why-ltv-uncertainty-matters" class="level1">
<h1>Part 1: Why LTV uncertainty matters</h1>
<section id="tldr-too-long-didnt-read" class="level3">
<h3 class="anchored" data-anchor-id="tldr-too-long-didnt-read">TL:DR (Too long, didn’t read)</h3>
<ul>
<li>The <em>Volume Function</em>, i.e.&nbsp;how many users you get for a given <em>Cost per User</em>, is crucial in determining the optimal <em>Cost per User</em></li>
<li>The derivate of the <em>Volume Function</em> around the optimal <em>Cost per User</em> and the uncertainty on the LTV estimate defines how much less we should bid from where you would bid, were uncertainty (i.e., the standard error of the prediction) 0</li>
<li>Depending on the <em>Volume Function</em> and uncertainty on the LTV, it may be worth bidding even 20% less than the optimal value if we had no uncertainty on the LTV value</li>
</ul>
<p>The rest of this document is organized into the following sections:</p>
<ol type="1">
<li><strong>Modelling digital advertisement</strong>: we explain the model for the operation of marketing campaigns in a digital platform and state that it has one goal: maximum profit. Initially, we define profit simply as the difference between earnings and cost, but then break those metrics down in LTV, <em>Cost per User</em>, and the number of users.</li>
<li><strong>The <em>Volume Function</em></strong>: The number of users acquired through a marketing campaign is defined by a function named <em>Volume Function</em> and its single input: the <em>Cost per User</em>. We describe the requirements for the <em>Volume Function</em> and introduce one possible solution.</li>
<li><strong>The profit curve, how the expected profit varies per <em>Cost per User</em>:</strong> With the volume function defined, we show how the profit for a given marketing campaign varies depending on the average <em>Cost per User</em>, if the LTV is kept constant</li>
<li><strong>The error associated with the predicted LTV</strong>: with the marketing model defined, we only need to determine the error associated with LTV. We assume it to be normally distributed around 0 and explain why that is a reasonable assumption</li>
<li><strong>The optimal bidding strategy under uncertainty</strong>: finally, we demonstrate how the error of LTV impacts the profitability of marketing campaigns and demonstrate which bidding strategy outperforms for different levels of LTV error and <em>Volume Functions</em></li>
<li><strong>Conclusion</strong>: we reinforce the reasons why estimating the uncertainty of LTV is vital to achieve high profitability in marketing campaigns and which strategy one should follow for each situation</li>
</ol>
</section>
<section id="modelling-digital-advertisement" class="level2">
<h2 class="anchored" data-anchor-id="modelling-digital-advertisement">1- Modelling digital advertisement</h2>
<p>The digital advertisement is rich with methods on how a monetary quantity (a bid, a bid cap, a budget, etc.) is connected to how many users - or leads, conversions, installs, subscribers - an advertiser acquires. For simplicity and without loss of generalization, we define for the rest of the document that we are reaching users for a digital product and use <em>Cost per User</em> as the lever that controls the volume (i.e., the quantity of the desired unit) acquired through advertisement, which can be easily exchanged to a bid or ROAS (Revenue over Ad Spend).</p>
<p>In a digital advertisement, the ultimate goal is to obtain a profit from the marketing campaign, defined as</p>
<p><img src="https://latex.codecogs.com/png.latex?%20Profit%20%5Ctriangleq%20Revenue%20-%20Costs"></p>
<p>, where <img src="https://latex.codecogs.com/png.latex?Revenue"> and <img src="https://latex.codecogs.com/png.latex?Cost"> can be further broken down:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20Profit%20=%20Users%20*%20(LTV_%7Buser%7D%20-%20Cost_%7Buser%7D)"></p>
<p>, where <img src="https://latex.codecogs.com/png.latex?Users"> stands for the number of users acquired from the marketing campaign, and <img src="https://latex.codecogs.com/png.latex?LTV_%7Buser%7D"> and <img src="https://latex.codecogs.com/png.latex?Cost_%7Buser%7D"> for the average LTV and Cost of those users, respectively.</p>
<p>But the number of users acquired from a marketing campaign depends on the digital platform, the advertised product, and how many we will put for a user. We are going to call this relationship <em>Volume Function</em> <img src="https://latex.codecogs.com/png.latex?f%5Cleft(Cost_%7Buser%7D%5Cright)">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20Installs%20%5Ctriangleq%20f%5Cleft(Cost_%7Buser%7D%5Cright)"></p>
<p>The resulting <img src="https://latex.codecogs.com/png.latex?Profit"> function thus becomes:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20Profit%20=%20f%5Cleft(Cost_%7Buser%7D%5Cright)%20*%20(LTV_%7Buser%7D%20-%20Cost_%7Buser%7D)"></p>
<p>And if the volume function and <img src="https://latex.codecogs.com/png.latex?LTV_%7Buser%7D"> are known, the <img src="https://latex.codecogs.com/png.latex?Cost_%7Buser%7D"> that delivers the highest <img src="https://latex.codecogs.com/png.latex?Profit"> can be found using an optimization function as [scipy.optimize.minimize] in Python. However, as we will show, it is less obvious when <img src="https://latex.codecogs.com/png.latex?LTV_%7Buser%7D"> is uncertain.</p>
</section>
<section id="the-volume-function-how-the-cost-per-user-defines-the-acquired-number-of-users" class="level2">
<h2 class="anchored" data-anchor-id="the-volume-function-how-the-cost-per-user-defines-the-acquired-number-of-users">2- The <em>Volume Function</em>: how the <em>Cost per User</em> defines the acquired number of users</h2>
<p>In the previous section, we introduced the <em>Volume Function</em> <img src="https://latex.codecogs.com/png.latex?f(x)"> but didn’t go into much detail. As this function defines the association between <em>Cost per User</em> and the number of users from a marketing campaign, it has to satisfy the following conditions:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?f(x)%20=%200">, <img src="https://latex.codecogs.com/png.latex?%5Cforall%20x%20%5Cleq%200">,
<ul>
<li>This is quite simple: an advertising platform will only show an ad to its user if it gains</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?f(x)"> is strictly monotonically non-decreasing
<ul>
<li>When we advertise on a platform, we first reach users not highly valued by other advertisers or who have a good match with our product. All else constant, the only way to get new customers is by paying a higher price <em>for those additional users</em> to win against the current winners. As a consequence, the average <em>Cost per User</em> increases.</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Clim_%7Bx%20%5Cto%20%5Cinfty%7D%20=%20D">
<ul>
<li>This condition states that a marketing platform has a maximum number of people we can reach, regardless of size. In the case of Meta and Google, this limit can be in the order of billions.</li>
</ul></li>
</ul>
<p>While many functions satisfy the requirements above, a simple one is the cumulative probability function of a log-normal distribution multiplied by a constant:</p>
<p><img src="https://latex.codecogs.com/png.latex?f%5Cleft(Cost_%7Buser%7D%5Cright)_%7BLog-Norm%20Distribution%7D%20=%20User_%7BLimit%7D*CDF_%7Blog-norm%7D(Cost_%7Buser%7D,%20%5Cmu,%20%5Csigma)"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?CDF_%7BLog-Norm%20Distribution%7D"> refers to the cumulative probability function of a log-normal distribution. While $ User_{limit}$ is unknown to the advertiser, it can be estimated from previous marketing campaigns:</p>
<p><img src="https://latex.codecogs.com/png.latex?Install_%7BRef%7D%20=%20%20User_%7BLimit%7D*CDF_%7Blog-norm%7D(Cost_%7Buser,%20reference%7D,%20%5Cmu,%20%5Csigma)"></p>
<p><img src="https://latex.codecogs.com/png.latex?User_%7BLimit%7D%20=%20%5Cfrac%7BInstall_%7BRef%7D%7D%7BCDF_%7Blog-norm%7D(Cost_%7Buser,%20reference%7D,%20%5Cmu,%20%5Csigma)%7D"></p>
<p>We will show for different log-normal distributions how the volume should vary per <img src="https://latex.codecogs.com/png.latex?Cost_%7Buser%7D">, and, consequently, the profit curve and the optimal bidding point. For that, we fix the following variables.</p>
<p><img src="https://latex.codecogs.com/png.latex?Cost_%7Buser,%20reference%7D%20=%202"> <img src="https://latex.codecogs.com/png.latex?E%5BLTV%5D%20=%202"> <img src="https://latex.codecogs.com/png.latex?Install_%7BRef%7D%20=%201000"></p>
<p>In addition, we will consider four different log-normal distributions for the <em>Volume Function</em>, with expected values of 0.5, 1.0, 1.5, and 2 and a standard deviation of 0.5 (for the normal distribution).</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> seaborn <span class="im" style="color: #00769E;">as</span> sns</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> joblib <span class="im" style="color: #00769E;">import</span> Parallel, delayed</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> List</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> src.VolumeAcquisition <span class="im" style="color: #00769E;">import</span> CumulativeLognormalVolume</span>
<span id="cb1-9"></span>
<span id="cb1-10">sns.set_style(<span class="st" style="color: #20794D;">'whitegrid'</span>)</span>
<span id="cb1-11">rng <span class="op" style="color: #5E5E5E;">=</span> np.random.default_rng(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb1-12">PLOT_WITHD_INCHES <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">20</span></span>
<span id="cb1-13">PLOT_HEIGHT_INCHES <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">10</span></span></code></pre></div>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># The fixed parameters specified before</span></span>
<span id="cb2-2">reference_volume <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1000</span></span>
<span id="cb2-3">reference_cpi <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">2.0</span></span>
<span id="cb2-4">reference_ltv <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">2.0</span></span>
<span id="cb2-5"></span>
<span id="cb2-6">lognormal_exp_values <span class="op" style="color: #5E5E5E;">=</span> [<span class="fl" style="color: #AD0000;">0.5</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="fl" style="color: #AD0000;">1.5</span>, <span class="fl" style="color: #AD0000;">2.0</span>] <span class="co" style="color: #5E5E5E;"># the expected values for the </span></span>
<span id="cb2-7">cpi_range <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="fl" style="color: #AD0000;">0.001</span>, <span class="fl" style="color: #AD0000;">6.5</span>, <span class="dv" style="color: #AD0000;">1000</span>) <span class="co" style="color: #5E5E5E;"># we want to consider cost per user between $0 and $6.5</span></span></code></pre></div>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;">def</span> generate_marketing_properties(</span>
<span id="cb3-2">    cpi_range: <span class="bu" style="color: null;">list</span>, </span>
<span id="cb3-3">    lognormal_expected_values: List[<span class="bu" style="color: null;">float</span>],</span>
<span id="cb3-4">    reference_volume: <span class="bu" style="color: null;">int</span>,</span>
<span id="cb3-5">    reference_cpi: <span class="bu" style="color: null;">float</span>,</span>
<span id="cb3-6">    reference_ltv: <span class="bu" style="color: null;">float</span></span>
<span id="cb3-7">):</span>
<span id="cb3-8">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;">    This class calculates (volume, revenue, profit, cost) for each CPI value in [cpi_range].</span></span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;">    The volume curve changes depending on the value from [volume_params], but it always gives [reference_volume] for [reference_cpi]</span></span>
<span id="cb3-11"><span class="co" style="color: #5E5E5E;">    In addition to the marketing properties, it also provides estimates on the CDF and PDF of the assumed distribution of volume by CPI</span></span>
<span id="cb3-12"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb3-13">    output_data <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb3-14">    <span class="cf" style="color: #003B4F;">for</span> exp_value <span class="kw" style="color: #003B4F;">in</span> lognormal_expected_values:</span>
<span id="cb3-15">        <span class="co" style="color: #5E5E5E;"># define how the volume behaves</span></span>
<span id="cb3-16">        volume_model <span class="op" style="color: #5E5E5E;">=</span> CumulativeLognormalVolume(reference_volume, reference_cpi, average<span class="op" style="color: #5E5E5E;">=</span>exp_value, standard_deviation<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>)</span>
<span id="cb3-17">        </span>
<span id="cb3-18">        <span class="co" style="color: #5E5E5E;"># calculate volume, and cdf for diferent cpis</span></span>
<span id="cb3-19">        volume <span class="op" style="color: #5E5E5E;">=</span> volume_model.calculate_volume(cpi_range)</span>
<span id="cb3-20">        cdf <span class="op" style="color: #5E5E5E;">=</span> volume_model.calculate_cdf(cpi_range)</span>
<span id="cb3-21">        pdf <span class="op" style="color: #5E5E5E;">=</span> volume_model.calculate_pdf(cpi_range)</span>
<span id="cb3-22">        df <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;">'cpi'</span>: cpi_range, <span class="st" style="color: #20794D;">'volume'</span>: volume, <span class="st" style="color: #20794D;">'cdf'</span>: cdf, <span class="st" style="color: #20794D;">'pdf'</span>: pdf})</span>
<span id="cb3-23">        </span>
<span id="cb3-24">        <span class="co" style="color: #5E5E5E;"># store which lognormal expected value was used</span></span>
<span id="cb3-25">        df[<span class="st" style="color: #20794D;">'expected_value'</span>] <span class="op" style="color: #5E5E5E;">=</span> exp_value</span>
<span id="cb3-26">        output_data.append(df)</span>
<span id="cb3-27"></span>
<span id="cb3-28">    <span class="co" style="color: #5E5E5E;"># merge the data from the different volume functions together</span></span>
<span id="cb3-29">    output_data <span class="op" style="color: #5E5E5E;">=</span> pd.concat(output_data)</span>
<span id="cb3-30">    </span>
<span id="cb3-31">    <span class="co" style="color: #5E5E5E;"># calculate the profit for each cpi</span></span>
<span id="cb3-32">    output_data[<span class="st" style="color: #20794D;">'profit'</span>] <span class="op" style="color: #5E5E5E;">=</span> output_data[<span class="st" style="color: #20794D;">'volume'</span>] <span class="op" style="color: #5E5E5E;">*</span> (reference_ltv <span class="op" style="color: #5E5E5E;">-</span> output_data[<span class="st" style="color: #20794D;">'cpi'</span>])</span>
<span id="cb3-33"></span>
<span id="cb3-34">    <span class="co" style="color: #5E5E5E;"># Cast the avg to make the seaborn interpret the values as category</span></span>
<span id="cb3-35">    output_data[<span class="st" style="color: #20794D;">'expected_value'</span>] <span class="op" style="color: #5E5E5E;">=</span> output_data[<span class="st" style="color: #20794D;">'expected_value'</span>].astype(<span class="bu" style="color: null;">str</span>)</span>
<span id="cb3-36">    <span class="cf" style="color: #003B4F;">return</span> output_data</span></code></pre></div>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># generate the volume and profit curves for our scenarios and store them in a pd.DataFrame</span></span>
<span id="cb4-2">log_norm_volume_data <span class="op" style="color: #5E5E5E;">=</span> generate_marketing_properties(</span>
<span id="cb4-3">    cpi_range,</span>
<span id="cb4-4">    lognormal_exp_values,</span>
<span id="cb4-5">    reference_volume,</span>
<span id="cb4-6">    reference_cpi,</span>
<span id="cb4-7">    reference_ltv</span>
<span id="cb4-8">    </span>
<span id="cb4-9">)</span></code></pre></div>
<p>Below you can see how the density probability functions with the selected parameters looks like</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">grid <span class="op" style="color: #5E5E5E;">=</span> sns.relplot(log_norm_volume_data, x<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cpi'</span>, y<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'pdf'</span>, hue<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'expected_value'</span>, kind<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'line'</span>)</span>
<span id="cb5-2">grid.figure.set_size_inches(PLOT_WITHD_INCHES, PLOT_HEIGHT_INCHES)</span>
<span id="cb5-3">plt.title(</span>
<span id="cb5-4">    <span class="st" style="color: #20794D;">'Probability density function (Y) versus cost per user (X), versus mean of the log-normal distribution'</span>, </span>
<span id="cb5-5">    font<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Avenir'</span>, </span>
<span id="cb5-6">    fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">24</span>, </span>
<span id="cb5-7">    loc<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'left'</span></span>
<span id="cb5-8">)</span></code></pre></div>
<pre><code>Text(0.0, 1.0, 'Probability density function (Y) versus cost per user (X), versus mean of the log-normal distribution')</code></pre>
<p><img src="https://raphaeltamaki.github.io/raphaeltamaki/posts/Forecasting Customer Lifetime Value - Why Uncertainty Matters/Different%20Volume%20Distributions.png" class="img-fluid"></p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">log_norm_volume_data <span class="op" style="color: #5E5E5E;">=</span> log_norm_volume_data[log_norm_volume_data[<span class="st" style="color: #20794D;">'cpi'</span>]<span class="op" style="color: #5E5E5E;">&lt;</span> <span class="fl" style="color: #AD0000;">2.5</span>]</span></code></pre></div>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">grid <span class="op" style="color: #5E5E5E;">=</span> sns.relplot(log_norm_volume_data, x<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cpi'</span>, y<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'volume'</span>, hue<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'expected_value'</span>, kind<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'line'</span>)</span>
<span id="cb8-2">grid.figure.set_size_inches(PLOT_WITHD_INCHES, PLOT_HEIGHT_INCHES)</span>
<span id="cb8-3">plt.title(</span>
<span id="cb8-4">    <span class="st" style="color: #20794D;">'Number of installs (Y) versus cost per install (X), versus mean of the log-normal distribution'</span>, </span>
<span id="cb8-5">    font<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Avenir'</span>, </span>
<span id="cb8-6">    fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">24</span>, </span>
<span id="cb8-7">    loc<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'left'</span>)</span></code></pre></div>
<pre><code>Text(0.0, 1.0, 'Number of installs (Y) versus cost per install (X), versus mean of the log-normal distribution')</code></pre>
<p><img src="https://raphaeltamaki.github.io/raphaeltamaki/posts/Forecasting Customer Lifetime Value - Why Uncertainty Matters/Volume%20Function.png" class="img-fluid"></p>
<p>Each curve can represent different advertisement platforms: the blue curve could be a small platform where most users can already be acquired with a relatively low cost of $4, while the red curve can represent a platform with many users and a lot of competition from other advertisers since there are a lot of users we can acquire - as the curve quickly increases after $2.</p>
</section>
<section id="the-profit-curve-how-the-expected-profit-varies-per-cost-per-user" class="level2">
<h2 class="anchored" data-anchor-id="the-profit-curve-how-the-expected-profit-varies-per-cost-per-user">3- The Profit Curve: how the expected profit varies per <em>Cost per User</em></h2>
<p>By using these curves in the <img src="https://latex.codecogs.com/png.latex?Profit"> function, we get the following profit curve by cost per user.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">grid <span class="op" style="color: #5E5E5E;">=</span> sns.relplot(log_norm_volume_data, x<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cpi'</span>, y<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'profit'</span>, hue<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'expected_value'</span>, kind<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'line'</span>)</span>
<span id="cb10-2">grid.figure.set_size_inches(PLOT_WITHD_INCHES, PLOT_HEIGHT_INCHES)</span>
<span id="cb10-3">plt.title(</span>
<span id="cb10-4">    <span class="st" style="color: #20794D;">'Predicted expected profit (Y) versus cost per install (X), versus mean of the log-normal distribution'</span>, </span>
<span id="cb10-5">    font<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Avenir'</span>, </span>
<span id="cb10-6">    fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">24</span>, </span>
<span id="cb10-7">    loc<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'left'</span>)</span></code></pre></div>
<pre><code>Text(0.0, 1.0, 'Predicted expected profit (Y) versus cost per install (X), versus mean of the log-normal distribution')</code></pre>
<p><img src="https://raphaeltamaki.github.io/raphaeltamaki/posts/Forecasting Customer Lifetime Value - Why Uncertainty Matters/Profit%20Curve.png" class="img-fluid"></p>
<p>Which all have slightly different optimal <img src="https://latex.codecogs.com/png.latex?Cost_%7Buser%7D"></p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">log_norm_volume_data.sort_values([<span class="st" style="color: #20794D;">'expected_value'</span>, <span class="st" style="color: #20794D;">'profit'</span>]).groupby([<span class="st" style="color: #20794D;">'expected_value'</span>])[<span class="st" style="color: #20794D;">'cpi'</span>].last().reset_index()</span></code></pre></div>
<div>


<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
expected_value
</th>
<th>
cpi
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0.5
</td>
<td>
1.360651
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1.0
</td>
<td>
1.536299
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1.5
</td>
<td>
1.653398
</td>
</tr>
<tr>
<th>
3
</th>
<td>
2.0
</td>
<td>
1.731464
</td>
</tr>
</tbody>

</table>
</div>
<p>While the highest profit isn’t relevant when comparing the curves, since we forced all the curves to provide the same number of users at $2, the ‘shape’ is. Notice how the profit curve drawn above is asymmetric around the optimal <img src="https://latex.codecogs.com/png.latex?Cost_%7Buser%7D"> for most curves, as the profit quickly drops as the <img src="https://latex.codecogs.com/png.latex?Cost_%7Buser%7D"> increases from its optimal point. This asymmetry will be essential to understand why and when the uncertainty on LTV matters.</p>
</section>
<section id="the-error-associated-with-the-predicted-ltv" class="level2">
<h2 class="anchored" data-anchor-id="the-error-associated-with-the-predicted-ltv">4- The error associated with the predicted LTV</h2>
<p>With the clear connection between <em>Cost per User</em> and profit, we can focus on LTV. The Lifetime Value of a user is, by definition, how much revenue a user generates in their lifetime, in other words, from the moment they started their ‘life’ as a user of a product until infinity. But we can’t use infinity in practice, in good part because we need a target to train the machine-learning models, so the lifetime value is usually defined as just a date ‘sufficiently away’ in the future.</p>
<p>The fact that the ‘real’ LTV is usually too far away in the future means that it cannot be used for practically any critical decision within a company. This means that the LTV used for such decisions will be an estimate, and as an estimate, we are sure of its exact value.</p>
<p>If we estimate the LTV of our users using any conventional machine-learning algorithm, one assumption that these models require is for the residual (basically the error) to be normally distributed. As such, we will assume that the LTV models’ error is (1) unbiased and (2) follow a normal distribution.</p>
<p><img src="https://latex.codecogs.com/png.latex?LTV%20%5Csim%20N(%5Cmu,%20%5Csigma)%20"></p>
<p><img src="https://latex.codecogs.com/png.latex?LTV_%7Bpredicted%7D%20=%20LTV%20+%20%5Cepsilon"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cepsilon%20%5Csim%20N(0,%20%5Cdelta)"></p>
<p>, where <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> is the residual and <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> is its standard devitiation.</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">rng <span class="op" style="color: #5E5E5E;">=</span> np.random.default_rng(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb13-2">ltv_error_std <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.5</span></span>
<span id="cb13-3">norm_dist <span class="op" style="color: #5E5E5E;">=</span> rng.normal(<span class="dv" style="color: #AD0000;">0</span>, ltv_error_std, <span class="dv" style="color: #AD0000;">10000</span>)</span>
<span id="cb13-4"></span>
<span id="cb13-5">grid <span class="op" style="color: #5E5E5E;">=</span> sns.histplot(norm_dist)</span>
<span id="cb13-6">grid.figure.set_size_inches(PLOT_WITHD_INCHES, PLOT_HEIGHT_INCHES)</span>
<span id="cb13-7">plt.title(</span>
<span id="cb13-8">    <span class="st" style="color: #20794D;">'Distribution of the error of the LTV predictions'</span>, </span>
<span id="cb13-9">    font<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Avenir'</span>, </span>
<span id="cb13-10">    fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">24</span>, </span>
<span id="cb13-11">    loc<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'left'</span>)</span></code></pre></div>
<pre><code>Text(0.0, 1.0, 'Distribution of the error of the LTV predictions')</code></pre>
<p><img src="https://raphaeltamaki.github.io/raphaeltamaki/posts/Forecasting Customer Lifetime Value - Why Uncertainty Matters/LTV%20Error%20Distribution.png" class="img-fluid"></p>
<p>Again, I will reinforce that LTV is a predicted metric, and as such <strong>until proven otherwise, it is what we believe to be true</strong>. That is the case for any metric, but for most metrics, ML models predict, it becomes clear relatively fast if the model was wrong or not. But it can take many months until signs appear of bias in the LTV predictions, which can mean <strong>several thousand, if not tens or hundreds of thousands of dollars, invested in marketing that are not coming back</strong></p>
<p>For example, assume five different scenarios where we keep the actual LTV at 2 dollars and use the <em>Volume Function</em> in orange from the first plot but have the estimated LTV to be $1, $1.5, $2, $2.5, or &nbsp;$3. If we know the <em>Volume Function</em> and we were to optimize for the predicted expected value of LTV without budget being a constrain, we would operate at the indicated <em>estimated optimal cpi</em>, believe we would obtain the <em>estimated profit</em> while in practice it would be the <em>real profit</em></p>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">possible_ltvs <span class="op" style="color: #5E5E5E;">=</span> [<span class="dv" style="color: #AD0000;">1</span>, <span class="fl" style="color: #AD0000;">1.5</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="fl" style="color: #AD0000;">2.5</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="fl" style="color: #AD0000;">3.5</span>]</span>
<span id="cb15-2">fixed_cpi <span class="op" style="color: #5E5E5E;">=</span> [<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb15-3">estimated_optimal_cpi <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb15-4"><span class="cf" style="color: #003B4F;">for</span> ltv <span class="kw" style="color: #003B4F;">in</span> possible_ltvs:</span>
<span id="cb15-5">    marketing_data <span class="op" style="color: #5E5E5E;">=</span> generate_marketing_properties(</span>
<span id="cb15-6">        cpi_range,</span>
<span id="cb15-7">        fixed_cpi,</span>
<span id="cb15-8">        reference_volume,</span>
<span id="cb15-9">        reference_cpi,</span>
<span id="cb15-10">        ltv</span>
<span id="cb15-11">    )</span>
<span id="cb15-12">    estimated_optimal_cpi.append(<span class="bu" style="color: null;">list</span>(marketing_data.sort_values([<span class="st" style="color: #20794D;">'profit'</span>])[<span class="st" style="color: #20794D;">'cpi'</span>])[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb15-13"></span>
<span id="cb15-14">estimated_optimal_cpi <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;">'cpi'</span>: estimated_optimal_cpi, <span class="st" style="color: #20794D;">'estimated_ltv'</span>: possible_ltvs})</span>
<span id="cb15-15"></span>
<span id="cb15-16">estimated_optimal_cpi <span class="op" style="color: #5E5E5E;">=</span> pd.merge(</span>
<span id="cb15-17">    log_norm_volume_data[log_norm_volume_data[<span class="st" style="color: #20794D;">'expected_value'</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'1.0'</span>],</span>
<span id="cb15-18">    estimated_optimal_cpi,</span>
<span id="cb15-19">    on<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cpi'</span></span>
<span id="cb15-20">)</span>
<span id="cb15-21">estimated_optimal_cpi[<span class="st" style="color: #20794D;">'estimated profit'</span>] <span class="op" style="color: #5E5E5E;">=</span> (estimated_optimal_cpi[<span class="st" style="color: #20794D;">'estimated_ltv'</span>] <span class="op" style="color: #5E5E5E;">-</span> estimated_optimal_cpi[<span class="st" style="color: #20794D;">'cpi'</span>])<span class="op" style="color: #5E5E5E;">*</span>estimated_optimal_cpi[<span class="st" style="color: #20794D;">'volume'</span>]</span>
<span id="cb15-22">estimated_optimal_cpi[<span class="st" style="color: #20794D;">'real profit'</span>] <span class="op" style="color: #5E5E5E;">=</span> estimated_optimal_cpi[<span class="st" style="color: #20794D;">'profit'</span>]</span></code></pre></div>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">estimated_ltv</th>
<th style="text-align: left;">cpi</th>
<th style="text-align: left;">volume</th>
<th style="text-align: left;">estimated profit</th>
<th style="text-align: left;">real profit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1.0</td>
<td style="text-align: left;">0.840210</td>
<td style="text-align: left;">34.971618</td>
<td style="text-align: left;">5.588107</td>
<td style="text-align: left;">40.559725</td>
</tr>
<tr class="even">
<td style="text-align: left;">1.5</td>
<td style="text-align: left;">1.204519</td>
<td style="text-align: left;">191.985179</td>
<td style="text-align: left;">56.728065</td>
<td style="text-align: left;">152.720654</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2.0</td>
<td style="text-align: left;">1.536299</td>
<td style="text-align: left;">470.453096</td>
<td style="text-align: left;">218.149430</td>
<td style="text-align: left;">218.149430</td>
</tr>
<tr class="even">
<td style="text-align: left;">2.5</td>
<td style="text-align: left;">1.829047</td>
<td style="text-align: left;">793.685368</td>
<td style="text-align: left;">532.525541</td>
<td style="text-align: left;">135.682857</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3.0</td>
<td style="text-align: left;">2.095773</td>
<td style="text-align: left;">1117.805605</td>
<td style="text-align: left;">1010.750263</td>
<td style="text-align: left;">-107.055342</td>
</tr>
<tr class="even">
<td style="text-align: left;">3.5</td>
<td style="text-align: left;">2.336476</td>
<td style="text-align: left;">1412.857895</td>
<td style="text-align: left;">1643.893396</td>
<td style="text-align: left;">-475.393446</td>
</tr>
</tbody>
</table>
<p>Notice the discrepancy between the estimated and actual profits when we overestimate LTV. While this discrepancy is minor when the predicted LTV is underestimated (and usually, getting more money than expected isn’t badly received news), the disparity quickly increases when the predictions are overestimated.</p>
<p>This behavior can be better understood when we plot the profit distribution when the standard deviation is 1 (i.e., 50% of the actual LTV). As shown below, while the profit is mostly positive, we have a situation where it is negative, as demonstrated by the long left tail.</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;"># See how the distribution of the profit is, when we are wrong about the LTV</span></span>
<span id="cb16-2"><span class="im" style="color: #00769E;">from</span> src.ProfitModel <span class="im" style="color: #00769E;">import</span> StandardModel</span>
<span id="cb16-3">volume_model <span class="op" style="color: #5E5E5E;">=</span> CumulativeLognormalVolume(reference_volume, reference_cpi, average<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, standard_deviation<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>)</span>
<span id="cb16-4">profit_model <span class="op" style="color: #5E5E5E;">=</span> StandardModel(volume_model, lifetime_value<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb16-5"></span>
<span id="cb16-6"><span class="co" style="color: #5E5E5E;"># calculate the profit</span></span>
<span id="cb16-7">cpis <span class="op" style="color: #5E5E5E;">=</span> rng.normal(reference_ltv, reference_ltv<span class="op" style="color: #5E5E5E;">*</span>ltv_error_std, <span class="dv" style="color: #AD0000;">10000</span>)</span>
<span id="cb16-8">profit_distribution <span class="op" style="color: #5E5E5E;">=</span> profit_model.calculate_profit(cpis)</span>
<span id="cb16-9"></span>
<span id="cb16-10">grid <span class="op" style="color: #5E5E5E;">=</span> sns.histplot(profit_distribution)</span>
<span id="cb16-11">grid.figure.set_size_inches(PLOT_WITHD_INCHES, PLOT_HEIGHT_INCHES)</span>
<span id="cb16-12">plt.title(</span>
<span id="cb16-13">    <span class="ss" style="color: #20794D;">f'Distribution of the profit when the LTV error is normally distributed with average 0 and standard deviation equal to </span><span class="sc" style="color: #5E5E5E;">{</span>ltv_error_std<span class="op" style="color: #5E5E5E;">*</span>reference_ltv<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>, </span>
<span id="cb16-14">    font<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Avenir'</span>, </span>
<span id="cb16-15">    fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">24</span>, </span>
<span id="cb16-16">    loc<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'left'</span>)</span></code></pre></div>
<pre><code>Text(0.0, 1.0, 'Distribution of the profit when the LTV error is normally distributed with average 0 and standard deviation equal to 1.0')</code></pre>
<p><img src="https://raphaeltamaki.github.io/raphaeltamaki/posts/Forecasting Customer Lifetime Value - Why Uncertainty Matters/Profit%20Distribution%20when%20LTV%20is%20uncertainty.png" class="img-fluid"></p>
<p>While one may think that a 50% error for a prediction is too high, that is quite common for a new product being launched, for a marketing platform being introduced, or for a novel optimization within an existing platform. I.E. for any case where there may not be much data available and the situation is sufficiently novel from what was seen before. So given the risk involved in incorrectly predicting and specially overestimating the LTV, how should we adapt the bidding strategy change for different degrees of uncertainty?</p>
</section>
</section>
<section id="bidding-strategy" class="level1">
<h1>5- Bidding Strategy</h1>
<p>A straightforward approach is <strong>bidding a fraction of the estimated LTV</strong>. The challenge is what fraction is ideal under each circumstance.</p>
<p>For that goal, we simulate the previous scenario 5000 times for each combination of LTV uncertainty (defined by the standard deviation of the error), and <em>Volume Function</em>, while always assuming that our LTV is unbiased. In each simulation, we</p>
<ol type="1">
<li>sample the predicted LTV from a normal distribution, with an expected value of being the actual LTV and standard deviation being a fraction from 0 to 0.4 of the it</li>
<li>we multiply the estimated LTV by a fraction, which can be from 0.3 to 1.2, and define it as a new estimated LTV</li>
<li>with this new predicted LTV and the knowledge of the <em>Volume Function</em>, we estimate the optimal <em>Cost per User</em></li>
<li>we use this <em>Cost per User</em> and obtain the actual profit</li>
<li>We calculate the average profit for each (Error Standard Deviation, <em>Volume Function</em>, LTV Fraction)</li>
<li>Then we see which LTV fraction provides the highest average profit for each (Error Standard Deviation, <em>Volume Function</em>)</li>
</ol>
<p>We will explain what is happening in a single simulation step-by-step and then show the results in the end</p>
<section id="step-by-step-explanation-of-the-simulation" class="level2">
<h2 class="anchored" data-anchor-id="step-by-step-explanation-of-the-simulation">5.1- Step-by-step explanation of the simulation</h2>
<p>We set up the parameters for the simulation</p>
<ul>
<li><code>sample_size</code> defines how many simulations we are doing. In the code it is called sample size because, effectively, each simulation is sampling a value for the LTV error from a normal distribution. In this step we are going to do 1 sample.</li>
<li><code>standard_deviation_of_ltv_error</code> defines the range considered for the simulation for the standard error of LTV. This value is relative to the expected LTV.</li>
<li><code>fraction_of_estimated_ltv</code> defines the fraction of the predicted LTV we use to bid. So if we predicted a LTV of $1.0 and the selected fraction is 0.8, we will re-scale the LTV to be $0.80 and find the optimal <em>Cost per User</em> under this scenario. While we state it is a fraction, we include values greater than 1 just to demonstrate that it is never better to ‘overpay’ for the <em>Volume Functions</em> used throughout this document</li>
</ul>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;">from</span> src.BidOptimizer <span class="im" style="color: #00769E;">import</span> StandardBidOptimizer</span>
<span id="cb18-2"></span>
<span id="cb18-3">sample_size <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb18-4">standard_deviation_of_ltv_error <span class="op" style="color: #5E5E5E;">=</span> [<span class="fl" style="color: #AD0000;">0.4</span>]</span>
<span id="cb18-5">fraction_of_estimated_ltv <span class="op" style="color: #5E5E5E;">=</span> [<span class="fl" style="color: #AD0000;">0.6</span>, <span class="fl" style="color: #AD0000;">0.8</span>]</span>
<span id="cb18-6">avg <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">2</span></span></code></pre></div>
<p>We then define the volume model with the previously mentioned</p>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">volume_model <span class="op" style="color: #5E5E5E;">=</span> CumulativeLognormalVolume(reference_volume, reference_cpi, avg, <span class="fl" style="color: #AD0000;">.5</span>)</span></code></pre></div>
<p>And now we create the bid optimizer object <code>bid_optim</code>. This class has 2 main methods: - <code>simulate()</code>: This method is going to extract samples from the normal distribution, then for each of the selected fractions we multiply the predicted LTV to obtain the adjusted LTV, which then is used as the <em>Cost per User</em>. Finally, the <em>Cost per User</em> is used to calculate the profit. - <code>calculate_bidding_strategy_results()</code>: This method uses the previous output, and calculates for each LTV standard error and fraction, the average profit. Then, for each standard error, it finds which LTV fraction provided the highest average profit</p>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">bid_optim <span class="op" style="color: #5E5E5E;">=</span> StandardBidOptimizer(</span>
<span id="cb20-2">    volume_model, </span>
<span id="cb20-3">    standard_deviation_of_ltv_error, </span>
<span id="cb20-4">    fraction_of_estimated_ltv, </span>
<span id="cb20-5">    reference_ltv_value<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">2.0</span>,</span>
<span id="cb20-6">    sample_size<span class="op" style="color: #5E5E5E;">=</span>sample_size)</span></code></pre></div>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;"># simulate the 2 scenarions (because we set sample_size to 2)</span></span>
<span id="cb21-2">sim_results <span class="op" style="color: #5E5E5E;">=</span> bid_optim.simulate()</span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;"># see the output from the simulation:</span></span>
<span id="cb21-5">sim_results</span></code></pre></div>
<div>


<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
estimated_ltv
</th>
<th>
ltv_fraction
</th>
<th>
cpi
</th>
<th>
profit
</th>
<th>
sd
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
2.121887
</td>
<td>
0.6
</td>
<td>
1.131382
</td>
<td>
16.937414
</td>
<td>
0.4
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2.121887
</td>
<td>
0.8
</td>
<td>
1.484203
</td>
<td>
76.374987
</td>
<td>
0.4
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1.584006
</td>
<td>
0.6
</td>
<td>
0.855907
</td>
<td>
2.074194
</td>
<td>
0.4
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1.584006
</td>
<td>
0.8
</td>
<td>
1.126308
</td>
<td>
16.435281
</td>
<td>
0.4
</td>
</tr>
</tbody>

</table>
</div>
<p>You can see that we have 2 rows for each <code>estimated_ltv</code> as a consequence of the 2 different <code>ltv_fraction</code> selected, resulting in the in the estimation of the optimal <em>Cost per User</em> <code>cpi</code>. This <code>cpi</code> is to obtain the actual <code>profit</code> you see there. Remeber that for all simulations the actual LTV is held at $2.0</p>
<p>We now calculate which of the LTV fractions gave the highest average profit</p>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">bid_optim.calculate_bidding_strategy_results(sim_results)</span>
<span id="cb22-2">bid_optim.bidding_strategy_data</span></code></pre></div>
<pre><code>/Users/raphaeltamaki/Documents/personal_git/lifetime_value_forecasting/src/BidOptimizer.py:80: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.
  self.bidding_strategy_data = self.bidding_strategy_data.groupby('sd')['mean_profit', 'std_profit', 'ltv_fraction'].first().reset_index()</code></pre>
<div>


<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
sd
</th>
<th>
mean_profit
</th>
<th>
std_profit
</th>
<th>
ltv_fraction
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0.4
</td>
<td>
46.405134
</td>
<td>
29.969853
</td>
<td>
0.8
</td>
</tr>
</tbody>

</table>
</div>
<p>Which in this case was 0.8, at $72.36</p>
</section>
<section id="simulation" class="level2">
<h2 class="anchored" data-anchor-id="simulation">5.2- Simulation</h2>
<p>Now that it is clear what is happening, we can find for each of the <em>Volume Functions</em> from before and for different levels of LTV standard error, which fraction gives the highest average profit</p>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">sample_size <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5000</span></span>
<span id="cb24-2">standard_deviation_of_ltv_error <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="fl" style="color: #AD0000;">0.001</span>, <span class="fl" style="color: #AD0000;">0.4</span>, <span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb24-3">fraction_of_estimated_ltv <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="fl" style="color: #AD0000;">0.3</span>, <span class="fl" style="color: #AD0000;">1.2</span>, <span class="dv" style="color: #AD0000;">20</span>)</span></code></pre></div>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">output_data <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb25-2"><span class="co" style="color: #5E5E5E;"># for each distribution of the Volume Function</span></span>
<span id="cb25-3"><span class="cf" style="color: #003B4F;">for</span> avg <span class="kw" style="color: #003B4F;">in</span> lognormal_exp_values:</span>
<span id="cb25-4">    <span class="co" style="color: #5E5E5E;"># set up the volume model</span></span>
<span id="cb25-5">    volume_model <span class="op" style="color: #5E5E5E;">=</span> CumulativeLognormalVolume(reference_volume, reference_cpi, avg, <span class="fl" style="color: #AD0000;">.5</span>)</span>
<span id="cb25-6">    </span>
<span id="cb25-7">    <span class="co" style="color: #5E5E5E;"># set up the class that will sample the standard error, and calculate the resulting bid and profit</span></span>
<span id="cb25-8">    bid_optim <span class="op" style="color: #5E5E5E;">=</span> StandardBidOptimizer(</span>
<span id="cb25-9">        volume_model, </span>
<span id="cb25-10">        standard_deviation_of_ltv_error, </span>
<span id="cb25-11">        fraction_of_estimated_ltv, </span>
<span id="cb25-12">        sample_size<span class="op" style="color: #5E5E5E;">=</span>sample_size)</span>
<span id="cb25-13">    </span>
<span id="cb25-14">    <span class="co" style="color: #5E5E5E;"># run the N=sample_size simulations</span></span>
<span id="cb25-15">    sim_results <span class="op" style="color: #5E5E5E;">=</span> bid_optim.simulate()</span>
<span id="cb25-16">    </span>
<span id="cb25-17">    <span class="co" style="color: #5E5E5E;"># calculate which LTV fraction gave the highest average profit for each LTV standard error level</span></span>
<span id="cb25-18">    bid_optim.calculate_bidding_strategy_results(sim_results)</span>
<span id="cb25-19">    </span>
<span id="cb25-20">    <span class="co" style="color: #5E5E5E;"># store the results</span></span>
<span id="cb25-21">    bid_optim.bidding_strategy_data[<span class="st" style="color: #20794D;">'lognormal_avg'</span>] <span class="op" style="color: #5E5E5E;">=</span> avg</span>
<span id="cb25-22">    output_data.append(bid_optim.bidding_strategy_data)</span></code></pre></div>
<pre><code>/Users/raphaeltamaki/Documents/personal_git/lifetime_value_forecasting/src/BidOptimizer.py:80: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.
  self.bidding_strategy_data = self.bidding_strategy_data.groupby('sd')['mean_profit', 'std_profit', 'ltv_fraction'].first().reset_index()
/Users/raphaeltamaki/Documents/personal_git/lifetime_value_forecasting/src/BidOptimizer.py:80: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.
  self.bidding_strategy_data = self.bidding_strategy_data.groupby('sd')['mean_profit', 'std_profit', 'ltv_fraction'].first().reset_index()
/Users/raphaeltamaki/Documents/personal_git/lifetime_value_forecasting/src/BidOptimizer.py:80: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.
  self.bidding_strategy_data = self.bidding_strategy_data.groupby('sd')['mean_profit', 'std_profit', 'ltv_fraction'].first().reset_index()
/Users/raphaeltamaki/Documents/personal_git/lifetime_value_forecasting/src/BidOptimizer.py:80: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.
  self.bidding_strategy_data = self.bidding_strategy_data.groupby('sd')['mean_profit', 'std_profit', 'ltv_fraction'].first().reset_index()</code></pre>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">plot_data <span class="op" style="color: #5E5E5E;">=</span> pd.concat(output_data)</span>
<span id="cb27-2">plot_data[<span class="st" style="color: #20794D;">'lognormal_avg'</span>] <span class="op" style="color: #5E5E5E;">=</span> plot_data[<span class="st" style="color: #20794D;">'lognormal_avg'</span>].astype(<span class="bu" style="color: null;">str</span>)</span>
<span id="cb27-3"></span>
<span id="cb27-4">grid <span class="op" style="color: #5E5E5E;">=</span> sns.relplot(plot_data, </span>
<span id="cb27-5">                   x<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sd'</span>, </span>
<span id="cb27-6">                   y<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ltv_fraction'</span>, </span>
<span id="cb27-7">                   hue<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'lognormal_avg'</span>, </span>
<span id="cb27-8">                   kind<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'line'</span>, </span>
<span id="cb27-9">                   facet_kws<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">'ylim'</span>: [<span class="dv" style="color: #AD0000;">0</span>, <span class="fl" style="color: #AD0000;">1.1</span>]}</span>
<span id="cb27-10">                  )</span>
<span id="cb27-11">grid.figure.set_size_inches(PLOT_WITHD_INCHES, PLOT_HEIGHT_INCHES)</span>
<span id="cb27-12">plt.title(</span>
<span id="cb27-13">    <span class="st" style="color: #20794D;">'Fraction of Cost per User with highest average profit when there is not uncertainty (Y) versus error level of LTV (X), versus mean for log-normal distribution'</span>,</span>
<span id="cb27-14">    font<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Avenir'</span>, </span>
<span id="cb27-15">    fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">24</span>, </span>
<span id="cb27-16">    loc<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'left'</span>)</span></code></pre></div>
<pre><code>Text(0.0, 1.0, 'Fraction of Cost per User with highest average profit when there is not uncertainty (Y) versus error level of LTV (X), versus mean for log-normal distribution')</code></pre>
<p><img src="https://raphaeltamaki.github.io/raphaeltamaki/posts/Forecasting Customer Lifetime Value - Why Uncertainty Matters/LTV%20Fraction%20Cost%20with%20highest%20average%20profit.png" class="img-fluid"></p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">grid <span class="op" style="color: #5E5E5E;">=</span> sns.relplot(plot_data, </span>
<span id="cb29-2">                   x<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'sd'</span>, </span>
<span id="cb29-3">                   y<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'mean_profit'</span>, </span>
<span id="cb29-4">                   hue<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'lognormal_avg'</span>, </span>
<span id="cb29-5">                   kind<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'line'</span>,</span>
<span id="cb29-6">                   facet_kws<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">'ylim'</span>: [<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">400</span>]}</span>
<span id="cb29-7">                  )</span>
<span id="cb29-8">grid.figure.set_size_inches(PLOT_WITHD_INCHES, PLOT_HEIGHT_INCHES)</span>
<span id="cb29-9">plt.title(</span>
<span id="cb29-10">    <span class="st" style="color: #20794D;">'Average profit from the optimal LTV fraction strategy (Y) versus error level of LTV (X), versus mean for log-normal distribution'</span>,</span>
<span id="cb29-11">    font<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Avenir'</span>, </span>
<span id="cb29-12">    fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">24</span>, </span>
<span id="cb29-13">    loc<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'left'</span>)</span></code></pre></div>
<pre><code>Text(0.0, 1.0, 'Average profit from the optimal LTV fraction strategy (Y) versus error level of LTV (X), versus mean for log-normal distribution')</code></pre>
<p><img src="https://raphaeltamaki.github.io/raphaeltamaki/posts/Forecasting Customer Lifetime Value - Why Uncertainty Matters/Average%20profit.png" class="img-fluid"></p>
<p>As expected, the greater the uncertainty of LTV, the more ‘conservative’ we should be on our marketing strategy. But that doesn’t only depend on the LTV uncertainty itself but also on the <em>Volume Function</em>. For <em>Volume Functions</em> where the profit curve is highly asymmetric around the optimal <em>Cost per User</em>, such as when <img src="https://latex.codecogs.com/png.latex?lognormal_%7Bavg%7D"> is 2 (red), even for a slight standard error of 0.1 we already have to bid less than the expected optimal point. However, we don’t need to be as conservative when the Profit Curve is more symmetric (i.e.&nbsp;the volume doesn’t increase as fast).</p>
<p>Notice also how the profit curve decreases similarly for all <em>Volume Functions</em> from where LTV error is close to 0 to where it is close to 0.4. However, the <strong>relative profit loss</strong> is much higher when the volume increase fast. While the loss for <img src="https://latex.codecogs.com/png.latex?lognormal_%7Bavg%7D"> equal to 0.5 (blue) from the two extremes is less than 9%, for <img src="https://latex.codecogs.com/png.latex?lognormal_%7Bavg%7D"> equal to 2 (red) the loss is 48%. That is a result from the need to bid further away from the optimal point and from the higher losses, when we overbid.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>6- Conclusion</h1>
<p>We demonstrated, under reasonable assumptions, that the LTV error and the Volume Function affect the expected profitability of market campaigns. We showed that the profit curve has different shapes depending on the Volume Function and becomes quite asymmetric around its optimal operation point.</p>
<p>As a consequence of this asymmetry, overestimation in the context of LTV prediction is much more dangerous than underestimation: the amount of money lost by overestimating a given amount is more significant than the unexpected money earned when we underestimate it by the same intensity.</p>
<p>Consequently, operating at a Cost per User below the expected optimum point is often beneficial. How much below it will depend on both the accuracy of the LTV predictions and how many more users can be acquired by an increase in the <em>Cost per User</em></p>
<p>All the code used to run the simulations and create the graphs in this document can be found in the <a href="https://github.com/raphaeltamaki/lifetime_value_forecasting">Lifetimevalue Forecasting</a> repository. You are invited to change change the <em>Volume Function</em> parameters or use other distributions, such as the Pareto, to best fit the marketing situation you see and find out how much to underbid to obtain maximum expected profitability.</p>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"></code></pre></div>


</section>

 ]]></description>
  <category>lifetime value</category>
  <category>marketing</category>
  <category>digital marketing</category>
  <guid>https://raphaeltamaki.github.io/raphaeltamaki/posts/Forecasting Customer Lifetime Value - Why Uncertainty Matters/index.html</guid>
  <pubDate>Wed, 12 Apr 2023 22:00:00 GMT</pubDate>
  <media:content url="https://raphaeltamaki.github.io/raphaeltamaki/posts/Forecasting Customer Lifetime Value - Why Uncertainty Matters/burning-money.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
